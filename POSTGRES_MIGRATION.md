# Postgres Cutover Playbook (Dev/Staging)

This document summarizes the exact commands and fixes we used to migrate from SQLite → PostgreSQL locally, plus hardened steps you can reuse to do it again without surprises.

Use this when you want to:
- Reset schema and bring Postgres to the Alembic head reliably
- Migrate data from the local SQLite `booking.db`
- Flip the backend to Postgres and smoke test

---

## Prerequisites

- Postgres is reachable (local or via Cloud SQL proxy) at `127.0.0.1:5432`
- You have a Postgres user/database; examples use:
  - User: `appuser`
  - Password (raw for pgloader): `k+le,U2kG1Gb0cp_`
  - DB: `appdb`
- psql installed; optional: pgloader installed (`brew install pgloader`)

Environment DSNs used in this doc:
- SQLAlchemy/psql DSN (percent-encoded password):
  - `postgresql://appuser:k%2Ble%2CU2kG1Gb0cp_@127.0.0.1:5432/appdb`
- pgloader DSN (RAW password, NO scheme in the template’s PG_DSN):
  - `appuser:k+le,U2kG1Gb0cp_@127.0.0.1:5432/appdb`

---

## One-time Code Hardening (already merged)

- Alembic env override reads DB_URL/SQLALCHEMY_DATABASE_URL; widens `alembic_version.version_num` to `VARCHAR(255)` when needed
- Added bootstrap migrations (booking_requests, bookings, quotes_v2) with idempotent enums and optional FKs
- Guarded/Idempotent index creation and enum conversions (USING casts); dialect-aware boolean defaults
- Runtime helpers normalize DATETIME → TIMESTAMP on Postgres; idempotent safe DDL only

You can use normal `alembic upgrade head` on fresh Postgres; if it stalls or conflicts, use the explicit sequence below.

---

## Scenario A — Fresh Postgres Bootstrap (clean schema)

From repo root `booking-app/`:

1) Drop and recreate schema (dev only — destructive)

```
psql "postgresql://appuser:k%2Ble%2CU2kG1Gb0cp_@127.0.0.1:5432/appdb" -c "DROP SCHEMA public CASCADE; CREATE SCHEMA public;"
```

2) Upgrade schema (Option 1: normal)

```
export DB_URL='postgresql+psycopg2://appuser:k%2Ble%2CU2kG1Gb0cp_@127.0.0.1:5432/appdb'
cd backend
alembic upgrade head
```

If Alembic reports multiple heads or stalls, use Option 2.

3) Upgrade schema (Option 2: explicit sequence to avoid topo-walk)

Run these in order; each prints the revision it applies. Skip any already applied.

```
export DB_URL='postgresql+psycopg2://appuser:k%2Ble%2CU2kG1Gb0cp_@127.0.0.1:5432/appdb'
cd backend

alembic upgrade 18708591c32a
alembic upgrade 3af18e2c6c76
alembic upgrade 4b9e2a61d4b1
alembic upgrade 662cfa8a683d
alembic upgrade 80a1b6c7d8a9
alembic upgrade 75934d6b3d55
alembic upgrade 4378675197d5
alembic upgrade 9b1c0d4a7c3c
alembic upgrade ae1027e1d3a1
alembic upgrade c8f4f76b2a6b
alembic upgrade d00fbf65c0b4
alembic upgrade 60101124c3b1
alembic upgrade b8d2e4f6a7c8
alembic upgrade b7c1d2e3f4a5
alembic upgrade e03ae2c1f3b6
alembic upgrade f23ad0e57c1d
alembic upgrade b0a1c2d3e4f5
alembic upgrade 05c00e13a615
alembic upgrade c9abfc3aaf86
alembic upgrade 20250823_01_add_event_type_guests
alembic upgrade 20250823_02_merge_heads
alembic upgrade 20250901_add_attachment_meta_to_messages
alembic upgrade 20250920_add_messages_request_id_id_index
alembic upgrade fe12ab34cd56
alembic upgrade fedcba987654
alembic upgrade abc123456789
alembic upgrade ee99a1b2c3d4
alembic upgrade f1a2b3c4d5e6
alembic upgrade def456abc123
```

Resolve final head merge:

```
# If alembic upgrade 5831ac500830 errors on overlapping heads, stamp head:
psql "postgresql://appuser:k%2Ble%2CU2kG1Gb0cp_@127.0.0.1:5432/appdb" -c "TRUNCATE alembic_version;"
psql "postgresql://appuser:k%2Ble%2CU2kG1Gb0cp_@127.0.0.1:5432/appdb" -c "INSERT INTO alembic_version(version_num) VALUES ('5831ac500830');"
# Verify
alembic current
```

4) Fix identity (if seeding warns on `service_categories.id`)

```
psql "postgresql://appuser:k%2Ble%2CU2kG1Gb0cp_@127.0.0.1:5432/appdb" -c "ALTER TABLE service_categories ALTER COLUMN id ADD GENERATED BY DEFAULT AS IDENTITY;"
```

---

## Scenario B — Data-only Migration (SQLite → Postgres)

Method 1 — With the helper script (pgloader must be installed):

```
# From repo root
chmod +x scripts/migrate_sqlite_to_pg.sh
# IMPORTANT: use RAW password, and for --pg pass NO scheme
WAIT_TIMEOUT=0 bash scripts/migrate_sqlite_to_pg.sh \
  --sqlite "$(pwd)/booking.db" \
  --pg "appuser:k+le,U2kG1Gb0cp_@127.0.0.1:5432/appdb"
```

Method 2 — Manual pgloader + sequence reset:

```
# Render the load file (RAW password; no scheme part in {{PG_DSN}})
SQLITE="$(pwd)/booking.db"
PG_NO_SCHEME="appuser:k+le,U2kG1Gb0cp_@127.0.0.1:5432/appdb"
TMP=$(mktemp -t migrate.XXXXXX.load)
sed -e "s#{{SQLITE_PATH}}#${SQLITE}#g" \
    -e "s#{{PG_DSN}}#${PG_NO_SCHEME}#g" \
    scripts/migrate.load > "$TMP"
# Optional: to avoid duplicate rows if partially loaded earlier
sed -i '' 's/WITH data only/WITH data only, truncate/' "$TMP"

# Run pgloader
pgloader "$TMP"

# Reset sequences (psql needs percent-encoded DSN)
psql "postgresql://appuser:k%2Ble%2CU2kG1Gb0cp_@127.0.0.1:5432/appdb" <<'SQL'
DO $$
DECLARE r record;
BEGIN
  FOR r IN
    SELECT c.relname AS table_name, a.attname AS col_name,
           pg_get_serial_sequence(quote_ident(n.nspname)||'.'||quote_ident(c.relname), a.attname) AS seq
    FROM pg_class c
    JOIN pg_namespace n ON n.oid = c.relnamespace
    JOIN pg_attribute a ON a.attrelid = c.oid AND a.attnum > 0
    JOIN pg_constraint k ON k.conrelid = c.oid AND k.contype='p' AND a.attnum = ANY(k.conkey)
    WHERE c.relkind='r' AND n.nspname NOT IN ('pg_catalog','information_schema')
  LOOP
    IF r.seq IS NOT NULL THEN
      EXECUTE format('SELECT setval(%L, COALESCE((SELECT MAX(%I) FROM %I.%I),0)+1, false)',
                     r.seq, r.col_name, 'public', r.table_name);
    END IF;
  END LOOP;
END $$;
SQL
```

Common pgloader fixes:
- Use RAW password for pgloader (no % encoding). Use percent-encoded DSN for psql/SQLAlchemy.
- If missing target columns/tables (e.g., `users.created_at`, `service_provider_profiles.cancellation_policy`, `service_categories`), add them first on Postgres:

```
# Examples
psql "postgresql://..." -c "ALTER TABLE users ADD COLUMN IF NOT EXISTS created_at TIMESTAMP;"
psql "postgresql://..." -c "ALTER TABLE users ADD COLUMN IF NOT EXISTS updated_at TIMESTAMP;"
psql "postgresql://..." -c "ALTER TABLE service_provider_profiles ADD COLUMN IF NOT EXISTS cancellation_policy TEXT;"
psql "postgresql://..." -c "CREATE TABLE IF NOT EXISTS service_categories (id integer PRIMARY KEY, name varchar UNIQUE NOT NULL, created_at timestamp, updated_at timestamp);"
```

---

## Scenario C — Flip Backend to Postgres & Smoke Test

```
# In the shell where you run the API
export SQLALCHEMY_DATABASE_URL='postgresql+psycopg2://appuser:k%2Ble%2CU2kG1Gb0cp_@127.0.0.1:5432/appdb'
cd backend
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

Verify:
- /auth/login, /auth/me
- Message threads (one WS per tab), attachments
- Quotes and bookings

---

## Known Pitfalls & Fixes (Reference)

- Alembic “Multiple heads” / “Ambiguous walk”
  - Use explicit `alembic upgrade <rev>` sequence, then merge to head
  - If a merge complains about missing parents in `alembic_version`, insert them (or `TRUNCATE alembic_version` then insert the final head) and `alembic current`

- Alembic “Duplicate enum” on Postgres
  - Migrations create enums with `checkfirst=True`; columns reference with `create_type=False` to avoid re-creating types

- Alembic `alembic_version` too short for long IDs
  - `ALTER TABLE alembic_version ALTER COLUMN version_num TYPE VARCHAR(255);`

- Boolean default mismatch (0/1 vs true/false)
  - For Postgres, use `DEFAULT FALSE/TRUE` (migrations adjusted)

- DATETIME on Postgres (runtime helpers)
  - DATETIME → TIMESTAMP mapping added; restart API

- pgloader DSN parsing / auth
  - Use RAW password; for the template’s `PG_DSN` use just `user:pass@host:port/db`

- zsh heredoc & SQL DO $$
  - In one-line `-c` commands, escape `$$` as `\$\$`
  - For heredoc, ensure the closing `SQL` is alone on its own line

---

## Quick Commands by Scenario

Fresh dev reset + schema:
```
psql "postgresql://appuser:k%2Ble%2CU2kG1Gb0cp_@127.0.0.1:5432/appdb" -c "DROP SCHEMA public CASCADE; CREATE SCHEMA public;"
export DB_URL='postgresql+psycopg2://appuser:k%2Ble%2CU2kG1Gb0cp_@127.0.0.1:5432/appdb'
cd backend && alembic upgrade head
```

Explicit schema path:
```
export DB_URL='postgresql+psycopg2://appuser:k%2Ble%2CU2kG1Gb0cp_@127.0.0.1:5432/appdb'
cd backend
# … run the explicit sequence listed above …
```

Normalize to final head if needed:
```
psql "postgresql://appuser:k%2Ble%2CU2kG1Gb0cp_@127.0.0.1:5432/appdb" -c "TRUNCATE alembic_version;"
psql "postgresql://appuser:k%2Ble%2CU2kG1Gb0cp_@127.0.0.1:5432/appdb" -c "INSERT INTO alembic_version(version_num) VALUES ('5831ac500830');"
cd backend && alembic current
```

Data-only migration:
```
# Script
WAIT_TIMEOUT=0 bash scripts/migrate_sqlite_to_pg.sh \
  --sqlite "$(pwd)/booking.db" \
  --pg "appuser:k+le,U2kG1Gb0cp_@127.0.0.1:5432/appdb"

# Manual
SQLITE="$(pwd)/booking.db"; PG_NO_SCHEME="appuser:k+le,U2kG1Gb0cp_@127.0.0.1:5432/appdb"
TMP=$(mktemp -t migrate.XXXXXX.load)
sed -e "s#{{SQLITE_PATH}}#${SQLITE}#g" -e "s#{{PG_DSN}}#${PG_NO_SCHEME}#g" scripts/migrate.load > "$TMP"
pgloader "$TMP"
psql "postgresql://appuser:k%2Ble%2CU2kG1Gb0cp_@127.0.0.1:5432/appdb" <<'SQL'
DO $$ DECLARE r record; BEGIN FOR r IN SELECT c.relname AS table_name, a.attname AS col_name, pg_get_serial_sequence(quote_ident(n.nspname)||'.'||quote_ident(c.relname), a.attname) AS seq FROM pg_class c JOIN pg_namespace n ON n.oid = c.relnamespace JOIN pg_attribute a ON a.attrelid = c.oid AND a.attnum > 0 JOIN pg_constraint k ON k.conrelid = c.oid AND k.contype='p' AND a.attnum = ANY(k.conkey) WHERE c.relkind='r' AND n.nspname NOT IN ('pg_catalog','information_schema') LOOP IF r.seq IS NOT NULL THEN EXECUTE format('SELECT setval(%L, COALESCE((SELECT MAX(%I) FROM %I.%I),0)+1, false)', r.seq, r.col_name, 'public', r.table_name); END IF; END LOOP; END $$;
SQL
```

Flip backend to Postgres & run:
```
export SQLALCHEMY_DATABASE_URL='postgresql+psycopg2://appuser:k%2Ble%2CU2kG1Gb0cp_@127.0.0.1:5432/appdb'
cd backend
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

That’s it. This playbook should let you repeat the cutover quickly and safely in the future.
